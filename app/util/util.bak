import os
import json
import sys
from pathlib import Path
import networkx as nx
import redis
import zlib
#import psycopg
#from psycopg.rows import dict_row
from pprint import pprint
from copy import deepcopy

class Util:
    asset_list: list = []
    translation: object
    graph: nx.Graph
    redis_client: redis
    #path_list: list = []
    lookup_cache: dict = {}
    possible_circular_references: list = []

    def __init__(self, filetype=None):
        self.graph = nx.Graph()
        self.redis_client = redis.Redis(host='localhost', port=6379, decode_responses=False)
        self.build_asset_list()
        self.build_lookup_cache()
        #self.path_list = self.redis_client.keys()
        #self.build_asset_list(filetype)
        #sys.setrecursionlimit(10000)

    def get_document_dict(self, path):
        asset: dict = self.get_asset_by_path(path)
        document: dict = None
        processed_document: dict = None
        
        if asset.get('document') is not None:
            document = json.loads(asset.get('document'))

        if asset.get('processed_document') is not None:
            processed_document = json.loads(asset.get('processed_document'))

        return {
            'document': document,
            'processed_document': processed_document
        }

    def map_path_to_file(self, path: str, root_path: str, asset_map: dict):
        asset: dict = asset_map.get(path)

        if asset is None:
            raise KeyError(path)

        asset_name: str = asset.get('Name')
        asset_container: str = asset.get('Container')

        container_path: object = Path(asset_container).parent
        filepath: str = os.path.join(root_path, container_path, asset_name) + '.json'

        return filepath

    def build_asset_list(self):
        for key in self.redis_client.scan_iter():
            self.asset_list.append(key.decode())

#    def build_asset_list(self, filetype: str = None):
#        connection_string = self.get_database_connection_string()

#        with psycopg.connect(conninfo=connection_string) as conn:
#            cursor: object = conn.cursor(name='asset_cursor', row_factory=dict_row)

#            if filetype is None:
#                query: str = 'select * from public.assets'
#                cursor.execute(query)
#            else:
#                query: str = 'select * from public.assets where filetype=%s'
#                cursor.execute(query, (filetype,))

#            #self.asset_list = cursor.fetchall()

#            while True:
#                rows = cursor.fetchmany(10000)
#                print('Fetched')

#                if not rows:
#                    return

#                for row in rows:
#                    path: str = str(row.get('path'))

#                    if path in self.path_list:
#                        continue

#                    source_row = json.dumps(row)
#                    compressed_row = zlib.compress(source_row.encode())

#                    self.redis_client.set(path, compressed_row)

#                self.redis_client.save()
#            #self.asset_list.append(row)

    def get_asset_list(self, asset_type: str = None):

        if asset_type is None:
            return self.asset_list
        else:
            matching_assets = [asset for asset in self.asset_list if asset.get('filetype') == asset_type]
            return matching_assets

    def build_lookup_cache(self):
        if self.redis_client.get('lookup_cache'):
            self.lookup_cache = self.get_asset_by_path('lookup_cache')

        for path in self.asset_list:
            asset: dict = self.get_asset_by_path(path)
            assert type(asset) is dict, asset

            filetype: str = asset.get('filetype')

            if self.lookup_cache.get(filetype) is None:
                self.lookup_cache.update({filetype: []})

            self.lookup_cache[filetype].append(path)

        deflated_asset = self.deflate_asset(self.lookup_cache)
        self.redis_client.set('lookup_cache', deflated_asset)

    def inflate_asset(self, asset):
        return json.loads(zlib.decompress(asset).decode())

    def deflate_asset(self, asset):
        return zlib.compress(json.dumps(asset).encode())

    def get_asset_by_path(self, path: str):
        return self.inflate_asset(self.redis_client.get(path))
#        matching_assets = [asset for asset in self.asset_list if asset.get('path') == path]
#        return matching_assets[0]

#    def get_processed_keys(self, asset_type: str = None):
#        connection_string = self.get_database_connection_string()
#        path_list: list = []

#        with psycopg.connect(conninfo=connection_string, row_factory=dict_row) as conn:
#            query: str = None
#            cursor: object = conn.cursor()
            
#            if asset_type is None:
#                query = 'select path from public.assets'
#                cursor.execute(query)
#            else:
#                query = 'select path from public.assets where filetype = %s'
#                cursor.execute(query, (asset_type,))

#            for row in cursor.fetchall():
#                path_list.append(row.get('path'))

#        return path_list

    def process_dict(self, dictionary: dict, parent_path: str, key_stack: str = ''):
        dictionary_copy: dict = deepcopy(dictionary)

        for key in dictionary.keys():
            item = dictionary.get(key)

            if key == 'timelineOverrideMasterData'\
            or key == 'timeline'\
            or key == 'affectionTimeline'\
            or key == 'curseUnbindingTimeline'\
            or key == 'givingTimeline'\
            or key == 'removingTimeline'\
            or key == 'resistTimeline'\
            or key == 'removeTimeline'\
            or key == 'shortTimeline'\
            or key == 'prerequisiteStages'\
            or key_stack == 'root.area.areaExpansion.difficultySettings.area'\
            or key_stack == 'root.area.areaExpansion.stageSettings.stage.area':
                #dictionary_copy.update({key: {'Omitted': True}})
                continue

            if type(item) is dict:
                if 'm_PathID' in item.keys():
                    path: str = item.get('m_PathID')
                    assert type(path) is str, item

                    if path != 0 and key != 'm_Script':
                        try:
                            recursive_document: dict = self.get_document(path=path, parent_path=parent_path, key_stack=f'{key_stack}.{key}')
                            assert type(recursive_document) is dict, recursive_document

                            dictionary_copy.update({key: recursive_document})
                        except RecursionError as ex:
                            print(f'Recursion Error 1: {path}')
                            #print(dictionary)
                            #raise ex
                    else:
                        continue
                else:
                    continue

            elif type(item) is list:
                exploded_list: list = []

                for element in item:
                    if type(element) is dict:
                        if 'm_PathID' in element.keys():
                            element_path: str = element.get('m_PathID')
                            assert type(element_path) is str, element_path

                            if element_path != 0:
                                try:
                                    recursive_document: dict = self.get_document(path=element_path, parent_path=parent_path, key_stack=f'{key_stack}.{key}')
                                    assert type(recursive_document) is dict, recursive_document

                                    exploded_list.append(recursive_document)
                                except RecursionError as ex:
                                    print(f'Recursion Error 2: {path}')
                                    #raise ex
                            else:
                                exploded_list.append(element)
                        else:
                            try:
                                processed_dict: dict = self.process_dict(dictionary=element, parent_path=parent_path, key_stack=f'{key_stack}.{key}')
                                assert type(processed_dict) is dict, processed_dict

                                exploded_list.append(processed_dict)
                            except RecursionError as ex:
                                print(f'Recursion Error 3: {path}')
                                #raise ex
                    else:
                        exploded_list.append(element)

                dictionary_copy.update({key: exploded_list})

        return dictionary_copy

    def get_document(self, path: str, parent_path: str = None, key_stack: str = None):
        circular_reference_check: dict = self.check_circular_references(path=path, parent_path=parent_path)

        if circular_reference_check is not None:
            return circular_reference_check

        document_dict: dict = self.get_document_dict(path)
        assert type(document_dict) is not None, document_dict

        if document_dict.get('processed_document') is not None:
            return document_dict.get('processed_document')

        processed_dict: dict = self.process_dict(dictionary=document_dict.get('document'), parent_path=path, key_stack=key_stack)
        assert type(processed_dict) is dict, document_dict

        return processed_dict

#    def get_database_connection_string(self):
#        return 'postgresql://postgres:postgres@localhost/postgres'

    def parse_asset(self, path: str):
        self.graph.clear()
        self.possible_circular_references = []

        document: dict = self.get_document(path=path, key_stack='root')
        assert type(document) is dict, document

        return document

    def check_circular_references(self, path: str, parent_path: str):
        if parent_path is not None:
            connected_edge_sets = list(nx.connected_components(self.graph))

            for connected_edge in connected_edge_sets:
                if path in connected_edge and parent_path in connected_edge:
                    combination_key: str = f'{path}:{parent_path}'
                    opposing_combination_key: str = f'{parent_path}:{path}'

                    if combination_key in self.possible_circular_references or opposing_combination_key in self.possible_circular_references:
                        if opposing_combination_key in self.possible_circular_references:
                            return {'CircularReference': True}
                    else:
                        self.possible_circular_references.append(combination_key)

        self.graph.add_node(path)

        if parent_path is not None:
            self.graph.add_edge(path, parent_path)

        return

#    def save_processed_document(self, asset_id: int, processed_document: dict, display_name: str):
#        connection_string = self.get_database_connection_string()

#        with psycopg.connect(conninfo=connection_string) as conn:
#            query: str = 'update public.assets set processed_document=%s, display_name=%s where id=%s'
#            cursor: object = conn.cursor()
#            cursor.execute(query, (json.dumps(processed_document), display_name, asset_id))

#    def save_document(self, asset_id: int, document: dict):
#        connection_string = self.get_database_connection_string()

#        with psycopg.connect(conninfo=connection_string) as conn:
#            query: str = 'update public.assets set document=%s where id=%s'
#            cursor: object = conn.cursor()
#            cursor.execute(query, (json.dumps(document), asset_id))
